{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled11.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNukBwW1Uljh",
        "outputId": "26bd1a2d-c163-410d-c3c6-3dacec224ba0"
      },
      "source": [
        "import string\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Activation, Dropout, LSTM, Flatten\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from scripts.dataExtract import loadData\n",
        "\n",
        "\n",
        "# %load_ext tensorboard \n",
        "# %tensorboard --logdir log   \n",
        "\n",
        "trainPath = \"data/train_eng.csv\"\n",
        "\n",
        "# Pre-processing data to find vector representations\n",
        "train_x, train_y = loadData(trainPath)\n",
        "\n",
        "# Creating vocabulary\n",
        "unique = list(set(\"\".join(string.ascii_lowercase[:26])))\n",
        "\n",
        "unique.sort()\n",
        "vocab = dict(zip(unique, range(1,len(unique)+1)))\n",
        "\n",
        "# Splitting data into train and val\n",
        "X_train, X_val, y_train, y_val = train_test_split(train_x, train_y)\n",
        "\n",
        "maxlen = 15\n",
        "len_vocab = len(vocab)\n",
        "# hyper-params\n",
        "\n",
        "learningRate = 0.001\n",
        "epoch = 100\n",
        "hidden_state_size = 5\n",
        "\n",
        "callback = EarlyStopping(monitor='val_loss', patience=15)\n",
        "mc = ModelCheckpoint('lstm_baseline_model.h5', monitor='val_loss', mode='min', verbose=1)\n",
        "reduce_lr_acc = ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=2, verbose=1, min_delta=1e-4, mode='max')\n",
        "\n",
        "def makemodel(maxlen, len_vocab, hidden_state_size, learningRate, lstm=True, fineTune = False):\n",
        "  model = Sequential()\n",
        "  if lstm:\n",
        "    model.add(Embedding(input_dim=len_vocab+1, output_dim=5))\n",
        "    model.add(LSTM(hidden_state_size, input_shape=(maxlen,len_vocab)))\n",
        "    # if fineTune:\n",
        "    #   model.add(Dropout(0.2))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "  else:\n",
        "    model.add(Embedding(input_dim=len_vocab+1, output_dim=5, input_length=maxlen))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(85, activity_regularizer=l2(0.002)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(1, activity_regularizer=l2(0.002)))\n",
        "    model.add(Activation('sigmoid'))\n",
        "  \n",
        "  model.compile(loss='BinaryCrossentropy', optimizer=Adam(learningRate),metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "\n",
        "lstm_baseline_model = makemodel(maxlen=maxlen, len_vocab=len_vocab, hidden_state_size=hidden_state_size, learningRate=learningRate, lstm=True, fineTune=False)\n",
        "lstm_baseline_model.summary()\n",
        "\n",
        "batch_size = 64\n",
        "tensorboard = TensorBoard(log_dir='log/{}'.format(\"LSTM Baseline Model\")) \n",
        "history = lstm_baseline_model.fit(X_train, y_train, batch_size=batch_size, epochs=100, verbose=1, validation_data =(X_val, y_val), callbacks = [tensorboard])\n",
        "\n",
        "lstm_baseline_model.save(\"lstmBaseLineModel.h5\")\n",
        "\n",
        "nn_baseline_model = makemodel(maxlen=maxlen, len_vocab=len_vocab, hidden_state_size=hidden_state_size, learningRate=learningRate, lstm=False)\n",
        "nn_baseline_model.summary()\n",
        "\n",
        "batch_size = 64\n",
        "tensorboard = TensorBoard(log_dir='log/{}'.format(\"Neural Network Baseline Model\")) \n",
        "history = nn_baseline_model.fit(X_train, y_train, batch_size=batch_size, epochs=100, verbose=1, validation_data =(X_val, y_val), callbacks=[callback, mc, reduce_lr_acc, tensorboard])\n",
        "\n",
        "nn_baseline_model.save(\"classicalNeuralNet.h5\")\n",
        "\n",
        "# hyper-params\n",
        "\n",
        "learningRate = 0.001\n",
        "epoch = 100\n",
        "batch_size = 64\n",
        "hidden_state_size = 25\n",
        "\n",
        "lstm_tuned_model = makemodel(maxlen=maxlen, len_vocab=len_vocab, hidden_state_size=hidden_state_size, learningRate=learningRate, lstm=True, fineTune=True)\n",
        "lstm_tuned_model.summary()\n",
        "batch_size = 64\n",
        "tensorboard = TensorBoard(log_dir='log/{}'.format(\"LSTM Tuned Model\")) \n",
        "history = lstm_tuned_model.fit(X_train, y_train, batch_size=batch_size, epochs=epoch, verbose=1, validation_data =(X_val, y_val), callbacks=[callback, tensorboard]) #  mc, reduce_lr_acc,\n",
        "\n",
        "lstm_tuned_model.save(\"LSTMfineTuned.h5\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_14 (Embedding)     (None, None, 5)           135       \n",
            "_________________________________________________________________\n",
            "lstm_12 (LSTM)               (None, 25)                3100      \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 1)                 26        \n",
            "=================================================================\n",
            "Total params: 3,261\n",
            "Trainable params: 3,261\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "977/977 [==============================] - 12s 10ms/step - loss: 0.6109 - accuracy: 0.6672 - val_loss: 0.5296 - val_accuracy: 0.7365\n",
            "Epoch 2/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.5295 - accuracy: 0.7411 - val_loss: 0.5160 - val_accuracy: 0.7498\n",
            "Epoch 3/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.5181 - accuracy: 0.7467 - val_loss: 0.5044 - val_accuracy: 0.7569\n",
            "Epoch 4/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.5089 - accuracy: 0.7537 - val_loss: 0.5049 - val_accuracy: 0.7557\n",
            "Epoch 5/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.4959 - accuracy: 0.7602 - val_loss: 0.4921 - val_accuracy: 0.7646\n",
            "Epoch 6/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.4726 - accuracy: 0.7722 - val_loss: 0.4722 - val_accuracy: 0.7770\n",
            "Epoch 7/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.4603 - accuracy: 0.7825 - val_loss: 0.4538 - val_accuracy: 0.7864\n",
            "Epoch 8/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.4600 - accuracy: 0.7811 - val_loss: 0.4587 - val_accuracy: 0.7823\n",
            "Epoch 9/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.4546 - accuracy: 0.7865 - val_loss: 0.4463 - val_accuracy: 0.7895\n",
            "Epoch 10/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.4533 - accuracy: 0.7842 - val_loss: 0.4473 - val_accuracy: 0.7889\n",
            "Epoch 11/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.4506 - accuracy: 0.7885 - val_loss: 0.4461 - val_accuracy: 0.7916\n",
            "Epoch 12/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.4512 - accuracy: 0.7887 - val_loss: 0.4400 - val_accuracy: 0.7941\n",
            "Epoch 13/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.4444 - accuracy: 0.7937 - val_loss: 0.4409 - val_accuracy: 0.7946\n",
            "Epoch 14/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.4445 - accuracy: 0.7906 - val_loss: 0.4398 - val_accuracy: 0.7921\n",
            "Epoch 15/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.4408 - accuracy: 0.7947 - val_loss: 0.4364 - val_accuracy: 0.7949\n",
            "Epoch 16/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.4423 - accuracy: 0.7928 - val_loss: 0.4371 - val_accuracy: 0.7967\n",
            "Epoch 17/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.4381 - accuracy: 0.7952 - val_loss: 0.4311 - val_accuracy: 0.7975\n",
            "Epoch 18/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.4413 - accuracy: 0.7941 - val_loss: 0.4290 - val_accuracy: 0.8001\n",
            "Epoch 19/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.4331 - accuracy: 0.7980 - val_loss: 0.4280 - val_accuracy: 0.8006\n",
            "Epoch 20/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.4308 - accuracy: 0.7992 - val_loss: 0.4255 - val_accuracy: 0.8031\n",
            "Epoch 21/100\n",
            "977/977 [==============================] - 9s 10ms/step - loss: 0.4283 - accuracy: 0.8011 - val_loss: 0.4300 - val_accuracy: 0.8006\n",
            "Epoch 22/100\n",
            "977/977 [==============================] - 9s 10ms/step - loss: 0.4267 - accuracy: 0.8013 - val_loss: 0.4229 - val_accuracy: 0.8029\n",
            "Epoch 23/100\n",
            "977/977 [==============================] - 9s 10ms/step - loss: 0.4196 - accuracy: 0.8051 - val_loss: 0.4209 - val_accuracy: 0.8053\n",
            "Epoch 24/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.4182 - accuracy: 0.8072 - val_loss: 0.4199 - val_accuracy: 0.8072\n",
            "Epoch 25/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.4249 - accuracy: 0.8023 - val_loss: 0.4218 - val_accuracy: 0.8056\n",
            "Epoch 26/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.4223 - accuracy: 0.8039 - val_loss: 0.4197 - val_accuracy: 0.8084\n",
            "Epoch 27/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.4151 - accuracy: 0.8099 - val_loss: 0.4197 - val_accuracy: 0.8055\n",
            "Epoch 28/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.4242 - accuracy: 0.8026 - val_loss: 0.4159 - val_accuracy: 0.8080\n",
            "Epoch 29/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.4167 - accuracy: 0.8085 - val_loss: 0.4169 - val_accuracy: 0.8081\n",
            "Epoch 30/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.4142 - accuracy: 0.8111 - val_loss: 0.4167 - val_accuracy: 0.8077\n",
            "Epoch 31/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.4119 - accuracy: 0.8110 - val_loss: 0.4164 - val_accuracy: 0.8107\n",
            "Epoch 32/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.4111 - accuracy: 0.8130 - val_loss: 0.4159 - val_accuracy: 0.8090\n",
            "Epoch 33/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.4086 - accuracy: 0.8149 - val_loss: 0.4124 - val_accuracy: 0.8106\n",
            "Epoch 34/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.4035 - accuracy: 0.8165 - val_loss: 0.4133 - val_accuracy: 0.8109\n",
            "Epoch 35/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.4078 - accuracy: 0.8121 - val_loss: 0.4120 - val_accuracy: 0.8096\n",
            "Epoch 36/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.4036 - accuracy: 0.8164 - val_loss: 0.4113 - val_accuracy: 0.8110\n",
            "Epoch 37/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.4060 - accuracy: 0.8157 - val_loss: 0.4085 - val_accuracy: 0.8129\n",
            "Epoch 38/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.4088 - accuracy: 0.8128 - val_loss: 0.4121 - val_accuracy: 0.8113\n",
            "Epoch 39/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.4010 - accuracy: 0.8178 - val_loss: 0.4101 - val_accuracy: 0.8121\n",
            "Epoch 40/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.3994 - accuracy: 0.8190 - val_loss: 0.4118 - val_accuracy: 0.8117\n",
            "Epoch 41/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.4023 - accuracy: 0.8177 - val_loss: 0.4108 - val_accuracy: 0.8120\n",
            "Epoch 42/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.4007 - accuracy: 0.8162 - val_loss: 0.4084 - val_accuracy: 0.8124\n",
            "Epoch 43/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.3983 - accuracy: 0.8204 - val_loss: 0.4090 - val_accuracy: 0.8125\n",
            "Epoch 44/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.3988 - accuracy: 0.8186 - val_loss: 0.4074 - val_accuracy: 0.8119\n",
            "Epoch 45/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.3961 - accuracy: 0.8196 - val_loss: 0.4092 - val_accuracy: 0.8126\n",
            "Epoch 46/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.3931 - accuracy: 0.8200 - val_loss: 0.4071 - val_accuracy: 0.8129\n",
            "Epoch 47/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.3953 - accuracy: 0.8198 - val_loss: 0.4115 - val_accuracy: 0.8108\n",
            "Epoch 48/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.3945 - accuracy: 0.8211 - val_loss: 0.4076 - val_accuracy: 0.8105\n",
            "Epoch 49/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.3966 - accuracy: 0.8189 - val_loss: 0.4083 - val_accuracy: 0.8129\n",
            "Epoch 50/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.3868 - accuracy: 0.8255 - val_loss: 0.4097 - val_accuracy: 0.8095\n",
            "Epoch 51/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.3899 - accuracy: 0.8216 - val_loss: 0.4109 - val_accuracy: 0.8120\n",
            "Epoch 52/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.3880 - accuracy: 0.8240 - val_loss: 0.4080 - val_accuracy: 0.8138\n",
            "Epoch 53/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.3906 - accuracy: 0.8204 - val_loss: 0.4106 - val_accuracy: 0.8095\n",
            "Epoch 54/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.3868 - accuracy: 0.8238 - val_loss: 0.4082 - val_accuracy: 0.8119\n",
            "Epoch 55/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.3899 - accuracy: 0.8235 - val_loss: 0.4057 - val_accuracy: 0.8119\n",
            "Epoch 56/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.3854 - accuracy: 0.8258 - val_loss: 0.4053 - val_accuracy: 0.8110\n",
            "Epoch 57/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.3885 - accuracy: 0.8252 - val_loss: 0.4055 - val_accuracy: 0.8124\n",
            "Epoch 58/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.3823 - accuracy: 0.8275 - val_loss: 0.4088 - val_accuracy: 0.8119\n",
            "Epoch 59/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.3903 - accuracy: 0.8238 - val_loss: 0.4078 - val_accuracy: 0.8147\n",
            "Epoch 60/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.3839 - accuracy: 0.8276 - val_loss: 0.4036 - val_accuracy: 0.8133\n",
            "Epoch 61/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.3850 - accuracy: 0.8257 - val_loss: 0.4066 - val_accuracy: 0.8144\n",
            "Epoch 62/100\n",
            "977/977 [==============================] - 9s 10ms/step - loss: 0.3817 - accuracy: 0.8270 - val_loss: 0.4081 - val_accuracy: 0.8121\n",
            "Epoch 63/100\n",
            "977/977 [==============================] - 9s 10ms/step - loss: 0.3789 - accuracy: 0.8285 - val_loss: 0.4042 - val_accuracy: 0.8139\n",
            "Epoch 64/100\n",
            "977/977 [==============================] - 9s 10ms/step - loss: 0.3807 - accuracy: 0.8283 - val_loss: 0.4050 - val_accuracy: 0.8147\n",
            "Epoch 65/100\n",
            "977/977 [==============================] - 9s 10ms/step - loss: 0.3769 - accuracy: 0.8293 - val_loss: 0.4056 - val_accuracy: 0.8149\n",
            "Epoch 66/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.3789 - accuracy: 0.8289 - val_loss: 0.4063 - val_accuracy: 0.8127\n",
            "Epoch 67/100\n",
            "977/977 [==============================] - 9s 10ms/step - loss: 0.3782 - accuracy: 0.8312 - val_loss: 0.4037 - val_accuracy: 0.8137\n",
            "Epoch 68/100\n",
            "977/977 [==============================] - 9s 10ms/step - loss: 0.3766 - accuracy: 0.8299 - val_loss: 0.4067 - val_accuracy: 0.8154\n",
            "Epoch 69/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.3763 - accuracy: 0.8312 - val_loss: 0.4050 - val_accuracy: 0.8158\n",
            "Epoch 70/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.3762 - accuracy: 0.8298 - val_loss: 0.4054 - val_accuracy: 0.8137\n",
            "Epoch 71/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.3736 - accuracy: 0.8318 - val_loss: 0.4066 - val_accuracy: 0.8136\n",
            "Epoch 72/100\n",
            "977/977 [==============================] - 9s 10ms/step - loss: 0.3749 - accuracy: 0.8303 - val_loss: 0.4102 - val_accuracy: 0.8104\n",
            "Epoch 73/100\n",
            "977/977 [==============================] - 10s 10ms/step - loss: 0.3698 - accuracy: 0.8354 - val_loss: 0.4078 - val_accuracy: 0.8143\n",
            "Epoch 74/100\n",
            "977/977 [==============================] - 10s 10ms/step - loss: 0.3738 - accuracy: 0.8310 - val_loss: 0.4069 - val_accuracy: 0.8133\n",
            "Epoch 75/100\n",
            "977/977 [==============================] - 9s 9ms/step - loss: 0.3791 - accuracy: 0.8305 - val_loss: 0.4055 - val_accuracy: 0.8154\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zv5Bq1fa9Kq",
        "outputId": "bf975483-6239-4189-f731-d5580a3c610f"
      },
      "source": [
        "from tensorflow import keras\n",
        "from scripts.dataExtract import loadData\n",
        "\n",
        "testPath = \"data/test_eng.csv\"\n",
        "test_x, test_y = loadData(testPath)\n",
        "\n",
        "lstm_baseline = keras.models.load_model(\"lstmBaseLineModel.h5\")\n",
        "results = lstm_baseline.evaluate(test_x, test_y, batch_size=128)\n",
        "print(\"LSTM Baseline test loss, test acc:\", results)\n",
        "\n",
        "neuralNetwork = keras.models.load_model(\"classicalNeuralNet.h5\")\n",
        "results = neuralNetwork.evaluate(test_x, test_y, batch_size=128)\n",
        "print(\"Neural Network test loss, test acc:\", results)\n",
        "\n",
        "\n",
        "lstm_tuned = keras.models.load_model(\"LSTMfineTuned.h5\")\n",
        "results = lstm_tuned.evaluate(test_x, test_y, batch_size=128)\n",
        "print(\"LSTM Tuned test loss, test acc:\", results)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "163/163 [==============================] - 1s 2ms/step - loss: 0.4311 - accuracy: 0.8021\n",
            "LSTM Baseline test loss, test acc: [0.43105417490005493, 0.8020843267440796]\n",
            "163/163 [==============================] - 0s 1ms/step - loss: 0.5106 - accuracy: 0.7572\n",
            "Neural Network test loss, test acc: [0.5106410980224609, 0.7572279572486877]\n",
            "163/163 [==============================] - 1s 3ms/step - loss: 0.4076 - accuracy: 0.8153\n",
            "LSTM Tuned test loss, test acc: [0.40758052468299866, 0.8152915239334106]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}